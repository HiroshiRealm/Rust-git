# RustGit

这是一个用 Rust 语言实现的简化版 Git。

## 功能

本项目旨在重新实现 Git 的一些核心功能，有助于深入了解 Git 的内部工作原理。

目前已实现以下命令：

*   `init`：初始化一个新的 Git 仓库。
*   `add`：将文件内容添加到索引。
*   `commit`：记录对仓库的更改。
*   `branch`：列出、创建或删除分支。
*   `checkout`：切换分支或恢复工作树文件。
*   `merge`：合并两个或多个开发历史。
*   `cat-file`：提供仓库对象的内容或类型和大小信息。
*   `status` 比较工作目录Workingdir,暂存区Index以及HEAD commit之间的区别
*   `rm`：从工作区和索引中删除文件。
*   `pull`：从远程仓库获取并集成。
*   `push`：更新远程引用以及关联的对象。
*   `fetch`：从另一个存储库下载对象和引用。
*   `remote`：管理远程仓库别名 (例如 `remote add origin <url>`)，配置存储在 `.git/config`。

### 接下来需要支持的命令


## 模块

项目主要包含以下模块：

*   `commands`：实现了各个 Git 命令的逻辑。
*   `repository`：处理 Git 仓库的内部结构，包括对象（objects）、引用（refs）和索引（index）。

## 如何使用

### 编译运行
cargo build --release

构建出来的是一个verbose output版本的git,执行每一个git命令之后都会输出一些内容,方便开发和调试用. 

如果是需要提交到oj的rust-git可执行文件,需要

"cargo build --features online_judge --release"

之后运行rust-git即可.

### 提交

运行make pack 即会自动生成一个符合提交格式的压缩包,自动使用 "cargo build --features online_judge --release" 编译

注意需要在x86 ISA下编译才行,macOS本地编译的结果提交后是无法运行的.


### Help

rust-git -h/help 即可

## 自动化测试

为了保证项目的稳定性和功能的正确性，我们编写了一套全面的端到端测试脚本，存放于 `tests/mytests/` 目录下。这些脚本会自动模拟真实的用户操作场景。

- `remote_alias_test.sh`: 核心功能测试。专门验证 `remote add` 添加别名后，能否成功使用该别名 (`origin`) 完成 `pull`, `fetch` 和 `push` 的完整工作流。
- `collaboration_test.sh`: 协作冲突测试。模拟两位客户端同时对一个远程仓库进行操作，验证当一位用户推送了新更改后，另一位用户的非快进 (Non-Fast-Forward) 推送会被服务器正确拒绝，从而保证数据安全。
- `gc_delta_compression_test.sh`: 垃圾回收与增量压缩测试。该测试完全使用我们自己实现的 `rust-git` 命令，模拟创建一个包含大文件及其微小修改的仓库。随后执行 `gc` 命令，并验证：1. 松散对象被清除；2. `.pack` 和 `.idx` 文件被正确创建；3. 最终的 packfile 体积显著小于原始对象之和，证明增量压缩有效。
- `local_bundle_test.sh`: 基础 HTTP 测试。验证基础的、通过网络进行 `pull` 和 `push` 的功能。

你可以通过在项目根目录运行 `bash ./tests/mytests/<script_name>.sh` 来执行这些测试。

## 远程命令实现 (Fetch, Pull, Push)

为了支持远程协作，我们实现了一套基于 HTTP 的 `fetch`, `pull` 和 `push` 命令。该实现的核心思路是利用 `git bundle` 的概念，将仓库的更新打包成单个文件进行传输。

### 核心理念：Git Bundle

我们没有直接传输零散的 Git 对象，而是将所有需要的 Git 对象和引用（Refs）打包成一个 `.tar.gz` 格式的压缩文件。这个单一的 bundle 文件包含了在两个仓库之间同步所需的所有信息。

- **Push 操作**: 客户端创建一个包含其新提交的 bundle 文件，并将其发送到服务器。
- **Fetch 操作**: 客户端从服务器请求一个包含最新历史的 bundle 文件，并在本地解包以更新其远程跟踪分支。

### 传输协议：哑 HTTP (Dumb HTTP)

我们实现了一个简单的"哑" HTTP 协议来交换 bundle 文件。

- **服务器**: 一个独立的 Rust 程序 (`src/bin/server.rs`)，使用 `axum` 框架构建。它在 `http://127.0.0.1:3000` 上监听，并提供一个端点：`/repo.bundle`。
  - `GET /repo.bundle`: 客户端执行 `fetch` 或 `pull` 时调用。服务器会实时将其本地 Git 仓库打包成一个 bundle 文件，并作为 HTTP 响应体发回。
  - `POST /repo.bundle`: 客户端执行 `push` 时调用。服务器接收 HTTP 请求体中的 bundle 文件，并在本地解包，以更新其仓库中的对象和分支。

- **客户端**: `fetch` 和 `push` 命令使用 `reqwest` 库来作为 HTTP 客户端。
  - `fetch`: 向服务器 URL 发送一个 `GET` 请求，并将收到的响应体（bundle 文件流）直接送入解包逻辑中。
  - `push`: 在内存中创建好 bundle 文件后，向服务器 URL 发送一个 `POST` 请求，将 bundle 作为请求体上传。

### 关键安全特性：非快进 (Non-Fast-Forward) 推送保护

为了防止在协作环境中意外覆盖他人的提交，服务器在处理 `push` 请求时实现了一个关键的安全检查。

- 在更新任何分支之前，服务器会检查当前分支的最新提交（HEAD）是否是客户端推送来的新提交的直接祖先。
- **快进 (Fast-Forward)**: 如果是直接祖先关系，说明推送是安全的，服务器会更新分支。
- **非快进 (Non-Fast-Forward)**: 如果不是直接祖先关系（意味着有其他人已经推送了新的更改），服务器会**拒绝**此次推送，并返回一个错误。这强制要求推送者必须先 `pull` 最新的代码，在本地合并后才能再次推送，从而保证了历史记录的完整性。

### 如何使用

1.  **启动服务器**:
    在一个终端中，使用以下命令为指定的 Git 仓库启动服务器。
    ```bash
    cargo run --bin server /path/to/your/server_repo
    ```

2.  **客户端操作**:
    在另一个终端中，你可以对该服务器执行远程操作。
    ```bash
    # 在你的本地仓库中
    # 1. 添加一个远程仓库的别名，指向服务器地址
    rust-git remote add origin http://127.0.0.1:3000/repo.bundle
    
    # 2. 从服务器拉取更新
    rust-git pull origin

    # 3. 将本地更新推送到服务器
    rust-git push origin
    
    # 你也可以直接对一个 URL 进行一次性推送
    rust-git push http://127.0.0.1:3000/repo.bundle
    ```

### 与真实 Git 协议的对比及未来改进

我们当前基于 HTTP 传输完整 bundle 的实现，虽然功能可用，但与 Git 的原生"智能协议"（Smart Protocol）相比，存在一些设计上的权衡，主要是为了简化实现。

**当前实现的优势与劣势：**

- **优势**:
  - **简单直观**: 整个逻辑非常清晰，将数据同步问题简化为了单个文件的传输问题。
  - **易于实现**: 无需实现复杂的"握手"和差异计算逻辑，复用了已有的 `bundle` 功能。

- **劣势 (性能和效率)**:
  - **数据冗余**: 我们的实现每次都会传输一个包含大量重复 Git 对象的 bundle 文件。即使用户只提交了一个很小的改动，整个仓库（或大部分）的对象也可能被重新打包并传输，造成了巨大的网络开销。
  - **服务器负载**: 服务器在每次 `fetch` 请求时都需要实时地将整个仓库打包并压缩成 `.tar.gz` 文件，这是一个消耗 CPU 和磁盘 I/O 的重量级操作。
  - **低效的引用发现**: 客户端必须下载整个 bundle 才能知道远程仓库有哪些分支和标签。

**Git 智能协议是如何工作的？**

真正的 Git 智能协议远比我们的实现高效。其大致流程如下：

1.  **握手 (Handshake)**: 客户端连接到服务器后，会先告诉服务器它本地拥有哪些分支的最新 commit ID。
2.  **差异计算**: 服务器根据客户端发来的信息，计算出客户端所缺少的、并且是这次请求所需要的最小对象集合。
3.  **瘦包 (Thin Pack)**: 服务器将这个最小化的对象集合打包成一个"瘦包"（thin packfile），并发送给客户端。这个包只包含客户端需要的数据，大大减少了传输量。

**未来可能的改进方向：**

为了让我们的实现更接近工业级标准，可以从以下几个方面进行改进：

1.  **实现协议握手**: 在客户端和服务器之间建立一个通信步骤，让它们可以交换各自的引用信息（分支和 commit ID）。
2.  **实现差异化打包**: 基于握手信息，在服务器端实现一个更智能的打包器，使其能够只打包客户端缺失的对象，生成"瘦包"。
3.  **实现 `upload-pack` 和 `receive-pack`**: 这两个是 Git 官方用来处理 `fetch` 和 `push` 流程的核心服务。最终目标是实现这两个服务，以达到与原生 Git 完全兼容和同样高效的水平。

## 架构探讨与未来展望

### 关于 `.git` 目录中的状态文件

在当前的实现中，我们像真实的 Git 一样，将仓库的状态"指针"存储在 `.git` 目录下的多个独立文件中。例如：
- `HEAD`: 指向当前所在的分支。
- `refs/heads/master`: 指向 `master` 分支的最新 commit ID。
- `refs/remotes/origin/master`: 指向远程 `origin` 的 `master` 分支的最新 commit ID。

这是一个非常简单和直观的设计，可以直接通过标准命令行工具 (`cat`, `echo`) 进行查看和操作，也反映了 Git 早期的设计哲学。

### 一个新的想法：统一的状态文件

一个有趣的架构改进思路是：能否将所有这些分散的状态"指针"整合到一个统一的、结构化的文件中（例如，一个名为 `.git/state` 的文件 (git中是有现成的例子的，比如说.git/config) ）？

**这种设计的潜在优势：**
1.  **原子性**: 更新单个文件通常比更新多个文件更具原子性。如果一次复杂的操作（如 `pull`）需要更新多个 ref，但在中途被打断，可能会导致仓库状态不一致。而更新单个文件可以更容易地保证事务的完整性。
2.  **性能**: 对于需要读取大量引用的操作，一次性读取并解析一个文件可能比多次单独读取分散的小文件性能更高，减少了文件 I/O 的开销。

**Git 的演化与权衡 (`packed-refs`)**

有趣的是，Git 的开发者们也早已意识到了这个问题。随着仓库中分支和标签数量的增多，`refs` 目录下的文件会变得越来越多，影响性能。因此，Git 引入了一个优化机制：`packed-refs` 文件。

- **`packed-refs` 文件**: 这是一个位于 `.git/packed-refs` 的单一文件。Git 会定期将 `refs/` 目录下大量不经常变动的引用（比如旧的分支或标签）打包到这个文件中，并删除原来的独立文件。
- **混合模式**: 现代 Git 采用的是一种**混合模式**。它会首先在独立的 loose ref 文件中寻找引用（例如 `refs/heads/master`），因为这些文件代表着最常被更新的引用。如果找不到，它才会去查询 `packed-refs` 这个"数据库"。

这种混合模式是性能与简单性之间一个绝佳的权衡。它既保留了直接操作高频更新的 ref (如 `HEAD` 和当前分支) 的简便性，又通过打包大量低频引用的方式解决了性能问题。

**未来的改进方向：**
我们当前的实现已经可以在 `bundle` 时创建 `packed-refs` 文件。一个非常有价值的未来改进方向，就是让我们的 `Repository` 模块也实现完整的混合模式：在读取引用时，能同时查询 loose ref 文件和 `packed-refs` 文件，并实现将 loose refs 打包进 `packed-refs` 的垃圾回收（`gc`）机制。这将使我们的实现在性能和健壮性上都向原生 Git 更进一步。

## 设计哲学：为何 Git 不立即进行增量压缩？

这是一个关于 Git 核心设计的常见问题：既然增量压缩（Delta Compression）能有效节省空间，为什么 Git 不在每次创建新对象（例如，每次 `git add` 或 `git commit`）时就立即进行，而要等到 `git gc` 或 `git push` 等操作时才统一处理呢？

答案在于 Git 对 **速度** 和 **效率** 的极致追求和权衡。

### 1. 保证核心命令的瞬时响应

Git 的设计目标之一是让 `git add` 和 `git commit` 这样的日常核心命令执行得尽可能快。当你修改并保存一个文件时，Git 会执行以下操作：
- **计算哈希**：对文件的完整内容进行 SHA-1 哈希计算。
- **压缩和存储**：使用 zlib 对内容进行压缩，然后以哈希值为文件名，将这个压缩后的版本作为一个独立的"松散对象"（Loose Object）存入 `.git/objects` 目录。

这个过程非常简单直接，只涉及一次压缩和一次文件写入，因此速度极快，几乎是瞬时的。

### 2. 增量压缩的巨大开销

与创建松散对象相反，增量压缩是一个计算密集型操作。为了找到最佳的压缩效果，Git 需要：
- **寻找最佳"基座"（Base Object）**：对于一个新对象，Git 需要在仓库中已存在的所有（或部分）对象中进行搜索和比较，找到一个与它最相似的"基座"对象。
- **计算差异（Delta）**：找到基座后，再计算新对象与基座之间的差异。

如果每次 `commit` 都执行这个过程，特别是对于一个大型仓库，这个搜索和计算的开销会让提交操作变得异常缓慢，严重影响开发体验。

### 3. "延迟工作"与"批量处理"的智慧

Git 的策略是"延迟"这种重度工作，并将其"批量处理"。它将昂贵的增量压缩操作推迟到了用户不经常执行的 `git gc`（垃圾回收）或网络传输 `git push` 等命令中。在这些操作中，Git 会批量地分析所有对象，找出相似的文件（例如，一个文件的不同版本），然后将其中一个作为基础版本，另一个仅存储它们之间的差异（delta）。通过这种方式，Git 在保证日常操作性能的同时，也实现了极致的长期存储效率。

### `gc` 命令与增量压缩实现

我们在 `rust-git` 中实现了 `gc` 命令的核心功能：将多个"松散对象"（loose objects）打包成一个 `.pack` 文件和对应的 `.idx` 索引文件，并在此过程中应用增量压缩以节省空间。下面将详细介绍这两种文件的格式以及未来的工作方向。

#### Packfile (`.pack`) 格式详解

Packfile 是 Git 用来高效存储多个对象的二进制文件。它由一个头部、一系列对象实体和一个尾部组成。

1.  **文件头 (12 字节)**
    *   **魔数 (4 字节):** 恒为 `'P', 'A', 'C', 'K'`。
    *   **版本号 (4 字节):** 我们实现的是版本2，即 `\x00\x00\x00\x02`。
    *   **对象数量 (4 字节):** 文件中包含的对象总数。

2.  **对象实体 (可变长度)**
    每个实体都由一个"实体头"和一个"实体数据"组成。
    *   **实体头:** 采用可变长度编码，记录了对象的类型和解压后的大小。
        *   第一个字节的最高位是"续读标记"，中间3位是对象类型，低4位是尺寸的最低有效位。
        *   对象类型主要有：`OBJ_COMMIT` (1), `OBJ_TREE` (2), `OBJ_BLOB` (3), 以及我们实现的增量类型 `OBJ_OFS_DELTA` (6)。
    *   **实体数据:** 经过 zlib 压缩后的数据。
        *   对于普通对象，数据内容是标准的 Git 对象格式 (`<type> <size>\0<content>`)。
        *   对于 `OBJ_OFS_DELTA` 增量对象，数据内容是它所依赖的"基础对象"的相对偏移量，以及描述两者差异的补丁指令。

3.  **文件尾 (20 字节)**
    *   文件内容的 SHA-1 校验和，确保文件的完整性。

#### 索引文件 (`.idx`) 格式详解

`.idx` 索引文件的存在是为了能快速在庞大的 `.pack` 文件中定位到任意一个对象，而无需从头扫描。

1.  **文件头 (8 字节)**
    *   **魔数 (4 字节):** 版本2的魔数恒为 `\xfftOc`。
    *   **版本号 (4 字节):** `\x00\x00\x00\x02`。

2.  **扇出表 (Fan-out Table, 1024 字节)**
    *   一个包含256个条目的表格。`fanout[i]` 记录了所有SHA-1值以小于等于`i`的字节开头的对象的总数。这个表极大地缩小了后续的搜索范围。

3.  **对象SHA-1列表 (N * 20 字节)**
    *   一个按字典序排序的、包含包内所有对象SHA-1哈希值的列表。

4.  **CRC校验和 (N * 4 字节)**
    *   每个对象在 packfile 中未压缩数据的 CRC32 校验和。目前我们的实现中暂时写入了占位符。

5.  **文件偏移量 (N * 4 字节)**
    *   每个对象在 `.pack` 文件中的起始位置的偏移量。

6.  **文件尾 (40 字节)**
    *   对应的 `.pack` 文件的 SHA-1 校验和，以及当前 `.idx` 文件自身的校验和。

##### `.idx` 如何加速对象读取？
扇出表（Fan-out Table）是 `.idx` 文件实现高效查找的关键。下面是一个对象查找的完整流程：
1.  **获取SHA-1首字节**：假设我们要查找SHA-1为 `A1B2...` 的对象。我们取其第一个字节 `0xA1`。
2.  **查询扇出表**：我们查看扇出表的第 `0xA1` 项（`fanout[161]`）和第 `0xA0` 项（`fanout[160]`）。`fanout[160]` 的值告诉我们，有多少个对象的SHA-1是以 `0xA0` 或更小的字节开头的。`fanout[161]` 则告诉我们有多少对象是以 `0xA1` 或更小的字节开头的。
3.  **定位搜索范围**：因此，所有以 `0xA1` 开头的对象，它们在后面"对象SHA-1列表"中的索引范围就在 `(fanout[160], fanout[161]]` 之间。这个范围通常非常小。
4.  **二分查找**：我们现在只需要在这个极小的范围内，对"对象SHA-1列表"进行二分查找，就能快速找到 `A1B2...` 的精确匹配及其对应的索引 `k`。
5.  **获取偏移量**：最后，我们直接在"文件偏移量"区域中查找第 `k` 个条目，就能得到该对象在 `.pack` 文件中的准确字节位置。
这个过程将一次全文件扫描（O(N)）降级为一次近乎常数时间的查找（O(log k)，k远小于N），使得即使在数GB大小的 packfile 中，对象读取也能在瞬间完成。

##### 扇出表大小的权衡：为何是256？
一个很自然的问题是：为什么扇出表的大小是256，而不是更大（例如65536）来让查找更快？

答案在于这是一个精心设计的 **工程权衡**。256这个数字并非随意选择，它直接对应了SHA-1哈希值第一个 **字节** 的256种可能性（0x00 到 0xff）。选择一个字节作为分区的依据，是在三个关键因素中取得的绝佳平衡：

1.  **空间开销 (Space Overhead):** 一个256条目的扇出表，每个条目为4字节整数，总共只占用 `256 * 4 = 1024` 字节（1KB）。这是一个非常小的、固定的开销。如果改用前两个字节作为分区依据，扇出表将需要 `65536` 个条目，占用 `256KB` 的空间。对于一个小型仓库来说，仅仅为了索引就增加 `256KB` 的固定开销是不理想的。

2.  **性能收益的边际递减 (Diminishing Returns):** 扇出表的主要目的是将一个巨大的列表（N个对象）缩小到一个可管理的小范围，以便进行二分查找。假设一个包里有一百万个对象，256条目的扇出表能将后续的二分查找范围缩小到约 `1,000,000 / 256 ≈ 3900` 个元素。二分查找3900个元素大约需要 `log₂(3900) ≈ 12` 次比较。如果使用65536条目的扇出表，范围会缩小到 `1,000,000 / 65536 ≈ 15` 个元素，大约需要 `log₂(15) ≈ 4` 次比较。我们用 `255KB` 的额外空间，仅仅换来了 **8次** 内存比较操作的节省。对于现代CPU来说，这点性能提升微乎其微，完全被增加的空间开销所抵消。

3.  **缓存友好性 (Cache-Friendliness):** 1KB大小的扇出表可以非常容易地被读入并安放在CPU的L1或L2缓存中。这意味着对扇出表的访问速度极快。而一个256KB的表则更有可能导致缓存未命中（Cache Miss），从而在内存访问上花费更多时间，可能会完全抵消掉上述微不足道的性能收益。

综上所述，256是一个在查找性能、存储效率和实现简洁性之间达到"甜点"的数字。它用极小的代价解决了核心瓶颈，是一个非常经典的工程决策。



#### `fossil-delta` 的选择

在实现增量压缩时，我们对库的选择经历了一个探索和修正的过程。我们最终选择了 `fossil-delta` 这个 crate，原因如下：

*   **兼容性**：Git 的增量压缩算法（源于 `libxdiff`）生成的是一种包含"复制"和"插入"指令的二进制差异。尽管 `fossil-delta` 的名字来源于 Fossil 版本控制系统，但它实现的也是同一种类型的增量算法，其输出格式与 Git packfile 的要求在原理上是兼容的。
*   **简洁性与纯粹性**：它是一个轻量级的、纯 Rust 实现的库，API 非常直观（`delta(base, new) -> Vec<u8>`），使得集成工作变得非常简单。
*   **有效性**：如此前的测试所示，该库在我们的项目中表现出色，成功地找到了文件间的差异并显著减小了仓库的体积。

值得一提的是，我们最初也考虑过其它方案，例如 `bsdiff`，但其格式与 Git 不兼容。我们也曾错误地尝试过一些名字相似但功能完全不同的库（例如 `git-delta`，一个 diff 查看工具），这个过程凸显了在技术选型时进行深入研究和验证的重要性。

#### 未来工作：深度集成的挑战

目前，我们成功实现了对象的"写入"打包，但一个完整的 Git 实现还需要解决"读取"和网络传输的挑战。

1.  **实现从 Packfile 中读取对象**
    *   **核心任务:** 这是最重要的下一步。当前所有读取对象的命令（如 `checkout`, `log`, `cat-file`）都只能读取松散对象。
    *   **实现路径:**
        1.  修改对象读取逻辑，使其优先检查所有 `.idx` 文件。
        2.  通过 `.idx` 的扇出表和SHA-1列表快速定位对象，获取其在 `.pack` 文件中的偏移量。
        3.  在 `.pack` 文件中，根据偏移量读取实体。如果它是普通对象，解压后直接返回。
        4.  如果它是增量对象，则需要递归地先读取它的"基础对象"，然后将差异补丁应用到基础对象上，最终还原出目标对象。这个递归解析是实现的关键和难点。

2.  **网络协议集成 (`push` & `fetch`)**
    *   当执行 `git push` 时，客户端和服务器需要协商确定哪些对象是服务器缺失的。
    *   客户端需要能动态地、在内存中创建一个只包含这些缺失对象的 "瘦包 (thin pack)"，然后将其作为整体发送给服务器。这远比逐个发送松散对象高效。

3.  **完善 `gc` 的回收逻辑**
    *   我们当前的 `gc` 会打包所有松散对象。一个真正的垃圾回收器会先从所有分支和标签出发，遍历提交图，找出所有"可达"的对象。只有那些"不可达"的对象才会被真正地删除，而可达的松散对象才会被打包。

完成以上工作，我们的 `rust-git` 才算真正拥有了与原生 Git 相媲美的存储和传输效率。
